# GAI: Technical Integration of DDPM and DIP

### **Accelerating DDPM with DIP-based Initial Priors**

**(1) HW Description**

In this example, you are asked to explore the possibility of using Deep Image Prior (DIP) to provide a quick initial prior for the Denoising Diffusion Probabilistic Model (DDPM) training process. The motivation behind this approach is to address the slow backward learning process in DDPM by leveraging the image-specific prior automatically learned by the CNN architecture in DIP.To implement this idea, you can start by training a DIP model on the target image for a relatively short period. The goal is to capture the high-level structures and patterns present in the image without overfitting to the noise. The trained DIP model can then be used to generate an initial prior for the DDPM training process. Next, you should modify the DDPM training algorithm to incorporate the DIP-based initial prior. Instead of starting from pure noise, the DDPM model can be initialized with the output of the DIP model. This initialization can provide a more informative starting point, potentially reducing the number of diffusion steps required for the DDPM model to converge. You should experiment with different DIP training durations and architectures to find the optimal balance between capturing meaningful image priors and computational efficiency. They should also investigate the impact of the DIP-based initialization on the quality and diversity of the generated samples from the DDPM model. To evaluate the effectiveness of this approach, you can compare the convergence speed and sample quality of the DDPM model with and without the DIP-based initial prior. They should provide quantitative metrics, such as the number of diffusion steps required to reach a certain level of sample quality, as well as qualitative comparisons of the generated samples. Furthermore, you can explore variations of this idea, such as using DIP to provide intermediate priors at different stages of the DDPM training process. They can also investigate the potential of using DIP to guide the noise estimation and denoising steps in DDPM, leveraging the learned image prior to improve the accuracy of these steps.

**(2) Introduction**

這次的作業我以一張貓咪圖片作為target image(cat.jpg), 分別以DIP模型和DDPM模型做訓練，DDPM又分為直接由原始圖cat.jpg下去跑模型以及第二種是利用DIP跑出來的生成圖再丟入DDPM模型進行訓練。最後在performance.py中比較三種訓練方式的效能結果，比較的效能項目包含PSNR以及generation time。

**(3) How To Run**

Step 1: Download all the folders and files

Step 2: Run the "dip_train.py" --> generate a training image every 100 epochs --> save the images and close the pop-out window to continue training

Step 3: Save the final output image as "dip_output.png" and copy it to the "ddpmwithdip" folder.

Step 4: The DIP training result will be display on the console (training loss)

Step 5: Goto the "ddpmwithdip" folder and run the "ddpm_train.py" file --> generate a training image every 100 epochs --> save the images and close the pop-out window to continue training

Step 6: Goto the "ddpmwithoutdip" folder and run the "ddpm_train.py" file --> generate a training image every 100 epochs --> save the images and close the pop-out window to continue training

Step 7: Compare the final images generated by different methods

Step 8: Run the "performance.py" to see the compared performance data. (PSNR/generation time/generated image)
